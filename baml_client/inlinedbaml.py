# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "classification.baml": "class Classification {\n  model_reasoning string @description(#\"\n    The reasoning steps of the model before outputing the result.\n  \"#)\n  chosen_theme Chosen_Theme\n}\n\nclass Chosen_Theme {\n    title string\n    description string\n}\n\n// Create a function to classify the json input\nfunction Classify(json: string) -> Classification {\n  client \"OllamaLlama3\" \n  prompt #\"\n    You are a classification assistant. Your job is to analyze a customer’s message and select the most appropriate theme from a provided list.\n\n    You will receive a JSON object with:\n    - a 'text' field: the message to classify\n    - a 'themes' field: a list of possible themes, each with a title and a description\n\n    Your task is to:\n    1. Read and understand the customer's message\n    2. Compare it carefully with each theme description\n    3. Select the best matching theme\n    4. Explain your reasoning clearly and concisely\n\n    Input JSON:\n    {{ json }}\n\n    Return your result in the following JSON format:\n    {{ ctx.output_format }}\n\n    Make sure your explanation includes why this theme was chosen over the others.\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_json {\n  functions [Classify]\n  args {\n    json #\"{\n    \"text\": \"I am calling because I have a problem with my internet connection\",\n    \"themes\": [\n        {\n            \"title\": \"Technical support\",\n            \"description\": \"The customer is calling for technical support\"\n        },\n        {\n            \"title\": \"Billing\",\n            \"description\": \"The customer is calling for billing issues\"\n        },\n        {\n            \"title\": \"Refund\",\n            \"description\": \"The customer is calling for a refund\"\n        }\n    ]\n}\n    \"#\n  }\n}\n",
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> OllamaLlama3 {\n  provider ollama\n  options {\n    model \"llama3\"\n  }\n}\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "form_completition.baml": "class Completed_Form {\n  title string\n  type string\n  properties Properties\n}\nclass Properties {\n    personal_info Personal_Info\n    contact_info Contact_Info\n}\n\nclass Personal_Info {\n    type string\n    properties Personal_Properties\n\n}\n\nclass Personal_Properties {\n    first_name string @description(#\"The customer's first name\"#)\n    last_name string @description(#\"The customer's last name\"#)\n    gender Gender @description(#\"The customer's gender\"#)\n}\n\nenum Gender {\n    Male\n    Female\n    Other\n}\n\nclass Contact_Info {\n    type string?\n    properties Contact_Properties?\n\n}\nclass Contact_Properties {\n    email string? @description(#\"The customer's email address\"#)\n    phone string? @description(#\"The customer's phone number\"#)\n    preferred_contact_method Preferred_Contact_Method? @description(#\"The customer's preferred method of contact\"#)\n    call_reasons string[]? @description(#\"The reasons for the call\"#)\n}\n\nenum Preferred_Contact_Method {\n    Email\n    Phone\n}\n\n// Create a function to complete a form\nfunction Form_Completetion(json: string) -> Completed_Form {\n  client \"OllamaLlama3\" \n  prompt #\"\n    You are a form extraction assistant.\n\n    Your task is to extract structured customer information from a transcript of a conversation between an agent and a customer.\n\n    The input will be a JSON object that contains a single key:\n    - `text`: the full transcript\n\n    Do not invent or assume information that was not stated.\n\n    Input transcript:\n    {{ json }}\n\n    Now return the completed form in the required structure :\n    {{ ctx.output_format }}\n  \"#\n}\n\ntest vaibhav_json {\n  functions [Form_Completetion]\n  args {\n    json #\"{\n    \"text\": \"Agent: Good morning! Thank you for reaching out. I’ll need to collect some basic details to assist you better. Could you please provide your first and last name? Customer: Sure! My name is John Doe. Agent: Thank you, John. May I also ask for your gender? Customer: I'd prefer not to share that at the moment. Agent: No problem at all. Now, for contact purposes, could you share your email address? Customer: Yes, my email is johndoe@example.com. Agent: Great! Do you have a phone number where we can reach you? Customer: I’d rather not provide that right now. Agent: That’s completely fine. How would you prefer us to contact you—by email or phone? Customer: Please contact me via Email. Agent: Understood! Lastly, can you share the reason for your call today? Customer: I’m not ready to specify that just yet. Agent: That’s okay, John! I’ve noted everything down. If you need any further assistance, feel free to reach out. Have a great day!\"\n}\n    \"#\n  }\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.204.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}

def get_baml_files():
    return _file_map